{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 11:51:46.084194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-25 11:51:46.084215: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../titanic-raw/train.csv')\n",
    "test = pd.read_csv('../titanic-raw/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 12), (418, 11))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape , test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(list(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fixing train_data\n",
    "\n",
    "train2 = train.copy()\n",
    "train2['Age'] = train2['Age'].replace(np.NAN, train2['Age'].mean())\n",
    "train['Age'].mean() , train2['Age'].mean()\n",
    "train2['Cabin'] = train2['Cabin'].replace(np.NAN, 'XX')\n",
    "train2['Cabin'].value_counts()\n",
    "train2['Embarked'] = train2['Embarked'].replace(np.NAN, 'YY')\n",
    "train2['Embarked'].value_counts()\n",
    "train2.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning test data\n",
    "\n",
    "test2 = test.copy()\n",
    "test2['Age'] = test2['Age'].replace(np.NAN, test2['Age'].mean())\n",
    "test['Age'].mean() , test2['Age'].mean()\n",
    "test2['Cabin'] = test2['Cabin'].replace(np.NAN, 'XX')\n",
    "test2['Cabin'].value_counts(dropna = False)\n",
    "test2['Fare'] = test2['Fare'].replace(np.NAN, test2['Fare'].mean())\n",
    "test['Fare'].mean() , test2['Fare'].mean()\n",
    "test2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLM = train2.copy()\n",
    "testLM = test2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    577\n",
      "1    314\n",
      "Name: Sex, dtype: int64\n",
      "     Survived  Pclass  Sex        Age  SibSp  Parch     Fare\n",
      "0           0       3    0  22.000000      1      0   7.2500\n",
      "1           1       1    1  38.000000      1      0  71.2833\n",
      "2           1       3    1  26.000000      0      0   7.9250\n",
      "3           1       1    1  35.000000      1      0  53.1000\n",
      "4           0       3    0  35.000000      0      0   8.0500\n",
      "..        ...     ...  ...        ...    ...    ...      ...\n",
      "886         0       2    0  27.000000      0      0  13.0000\n",
      "887         1       1    1  19.000000      0      0  30.0000\n",
      "888         0       3    1  29.699118      1      2  23.4500\n",
      "889         1       1    0  26.000000      0      0  30.0000\n",
      "890         0       3    0  32.000000      0      0   7.7500\n",
      "\n",
      "[891 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "trainLM.Sex.value_counts()\n",
    "\n",
    "m1 = {'male':0, 'female':1}\n",
    "trainLM['Sex'] = trainLM['Sex'].map(m1)\n",
    "testLM['Sex'] = testLM['Sex'].map(m1) \n",
    "\n",
    "# note : running this snippet 2nd time creates NaN value\n",
    "print(trainLM['Sex'].value_counts())\n",
    "testLM['Sex'].value_counts()\n",
    "trainLM.dtypes\n",
    "testLM.dtypes\n",
    "trainLM2 = trainLM.iloc[:, [1,2,4,5,6,7,9,]]\n",
    "print(trainLM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLM2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLM2 = testLM.iloc[:, [1,3,4,5,6,8]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 11:51:48.257898: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-25 11:51:48.257932: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-25 11:51:48.257952: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (CoderCatA5Pop): /proc/driver/nvidia/version does not exist\n",
      "2022-06-25 11:51:48.258252: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#K time to prep train data for neural network\n",
    "X=tf.convert_to_tensor(trainLM2.drop('Survived',axis=1))\n",
    "Y=tf.convert_to_tensor(trainLM2['Survived'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(891, 6), dtype=float64, numpy=\n",
       "array([[ 3.        ,  0.        , 22.        ,  1.        ,  0.        ,\n",
       "         7.25      ],\n",
       "       [ 1.        ,  1.        , 38.        ,  1.        ,  0.        ,\n",
       "        71.2833    ],\n",
       "       [ 3.        ,  1.        , 26.        ,  0.        ,  0.        ,\n",
       "         7.925     ],\n",
       "       ...,\n",
       "       [ 3.        ,  1.        , 29.69911765,  1.        ,  2.        ,\n",
       "        23.45      ],\n",
       "       [ 1.        ,  0.        , 26.        ,  0.        ,  0.        ,\n",
       "        30.        ],\n",
       "       [ 3.        ,  0.        , 32.        ,  0.        ,  0.        ,\n",
       "         7.75      ]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making our model\n",
    "\n",
    "model=Sequential([\n",
    "      normalizer,\n",
    "      tf.keras.layers.Input(shape=(6,)),\n",
    "      Dense(units=25,activation=\"relu\"),\n",
    "      Dense(units=15,activation=\"relu\"),\n",
    "      Dense(units=5,activation=\"relu\"),\n",
    "      Dense(units=1,activation=\"sigmoid\"),\n",
    "      \n",
    "\n",
    "  ])\n",
    "model.compile(loss=BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "class EvalCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "       pass\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs=None):\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "28/28 [==============================] - 0s 681us/step - loss: 0.6704 - accuracy: 0.6745\n",
      "Epoch 2/100000\n",
      "28/28 [==============================] - 0s 703us/step - loss: 0.6611 - accuracy: 0.6925\n",
      "Epoch 3/100000\n",
      "28/28 [==============================] - 0s 671us/step - loss: 0.6522 - accuracy: 0.6981\n",
      "Epoch 4/100000\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.6439 - accuracy: 0.7037\n",
      "Epoch 5/100000\n",
      "28/28 [==============================] - 0s 734us/step - loss: 0.6356 - accuracy: 0.7160\n",
      "Epoch 6/100000\n",
      "28/28 [==============================] - 0s 726us/step - loss: 0.6273 - accuracy: 0.7284\n",
      "Epoch 7/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6185 - accuracy: 0.7374\n",
      "Epoch 8/100000\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.6090 - accuracy: 0.7385\n",
      "Epoch 9/100000\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.6002 - accuracy: 0.7452\n",
      "Epoch 10/100000\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.5918 - accuracy: 0.7464\n",
      "Epoch 11/100000\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.5837 - accuracy: 0.7464\n",
      "Epoch 12/100000\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.5762 - accuracy: 0.7441\n",
      "Epoch 13/100000\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.5688 - accuracy: 0.7475\n",
      "Epoch 14/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7542\n",
      "Epoch 15/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7531\n",
      "Epoch 16/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.7553\n",
      "Epoch 17/100000\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.5430 - accuracy: 0.7643\n",
      "Epoch 18/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.7621\n",
      "Epoch 19/100000\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.5319 - accuracy: 0.7621\n",
      "Epoch 20/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7621\n",
      "Epoch 21/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7621\n",
      "Epoch 22/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7632\n",
      "Epoch 23/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7632\n",
      "Epoch 24/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7643\n",
      "Epoch 25/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7643\n",
      "Epoch 26/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7654\n",
      "Epoch 27/100000\n",
      "28/28 [==============================] - 0s 720us/step - loss: 0.4976 - accuracy: 0.7677\n",
      "Epoch 28/100000\n",
      "28/28 [==============================] - 0s 698us/step - loss: 0.4945 - accuracy: 0.7666\n",
      "Epoch 29/100000\n",
      "28/28 [==============================] - 0s 669us/step - loss: 0.4916 - accuracy: 0.7677\n",
      "Epoch 30/100000\n",
      "28/28 [==============================] - 0s 668us/step - loss: 0.4888 - accuracy: 0.7677\n",
      "Epoch 31/100000\n",
      "28/28 [==============================] - 0s 623us/step - loss: 0.4862 - accuracy: 0.7654\n",
      "Epoch 32/100000\n",
      "28/28 [==============================] - 0s 624us/step - loss: 0.4839 - accuracy: 0.7666\n",
      "Epoch 33/100000\n",
      "28/28 [==============================] - 0s 625us/step - loss: 0.4817 - accuracy: 0.7666\n",
      "Epoch 34/100000\n",
      "28/28 [==============================] - 0s 672us/step - loss: 0.4793 - accuracy: 0.7666\n",
      "Epoch 35/100000\n",
      "28/28 [==============================] - 0s 763us/step - loss: 0.4773 - accuracy: 0.7688\n",
      "Epoch 36/100000\n",
      "28/28 [==============================] - 0s 670us/step - loss: 0.4755 - accuracy: 0.7688\n",
      "Epoch 37/100000\n",
      "28/28 [==============================] - 0s 640us/step - loss: 0.4737 - accuracy: 0.7710\n",
      "Epoch 38/100000\n",
      "28/28 [==============================] - 0s 664us/step - loss: 0.4719 - accuracy: 0.7744\n",
      "Epoch 39/100000\n",
      "28/28 [==============================] - 0s 667us/step - loss: 0.4704 - accuracy: 0.7789\n",
      "Epoch 40/100000\n",
      "28/28 [==============================] - 0s 655us/step - loss: 0.4688 - accuracy: 0.7879\n",
      "Epoch 41/100000\n",
      "28/28 [==============================] - 0s 628us/step - loss: 0.4672 - accuracy: 0.7901\n",
      "Epoch 42/100000\n",
      "28/28 [==============================] - 0s 645us/step - loss: 0.4658 - accuracy: 0.7901\n",
      "Epoch 43/100000\n",
      "28/28 [==============================] - 0s 647us/step - loss: 0.4644 - accuracy: 0.7901\n",
      "Epoch 44/100000\n",
      "28/28 [==============================] - 0s 674us/step - loss: 0.4631 - accuracy: 0.7924\n",
      "Epoch 45/100000\n",
      "28/28 [==============================] - 0s 669us/step - loss: 0.4618 - accuracy: 0.7924\n",
      "Epoch 46/100000\n",
      "28/28 [==============================] - 0s 669us/step - loss: 0.4608 - accuracy: 0.7924\n",
      "Epoch 47/100000\n",
      "28/28 [==============================] - 0s 621us/step - loss: 0.4596 - accuracy: 0.7946\n",
      "Epoch 48/100000\n",
      "28/28 [==============================] - 0s 679us/step - loss: 0.4587 - accuracy: 0.7946\n",
      "Epoch 49/100000\n",
      "28/28 [==============================] - 0s 794us/step - loss: 0.4576 - accuracy: 0.7991\n",
      "Epoch 50/100000\n",
      "28/28 [==============================] - 0s 745us/step - loss: 0.4567 - accuracy: 0.7980\n",
      "Epoch 51/100000\n",
      "28/28 [==============================] - 0s 731us/step - loss: 0.4559 - accuracy: 0.7991\n",
      "Epoch 52/100000\n",
      "28/28 [==============================] - 0s 667us/step - loss: 0.4549 - accuracy: 0.7991\n",
      "Epoch 53/100000\n",
      "28/28 [==============================] - 0s 635us/step - loss: 0.4539 - accuracy: 0.7991\n",
      "Epoch 54/100000\n",
      "28/28 [==============================] - 0s 658us/step - loss: 0.4532 - accuracy: 0.8002\n",
      "Epoch 55/100000\n",
      "28/28 [==============================] - 0s 685us/step - loss: 0.4524 - accuracy: 0.7991\n",
      "Epoch 56/100000\n",
      "28/28 [==============================] - 0s 687us/step - loss: 0.4516 - accuracy: 0.8025\n",
      "Epoch 57/100000\n",
      "28/28 [==============================] - 0s 640us/step - loss: 0.4509 - accuracy: 0.8047\n",
      "Epoch 58/100000\n",
      "28/28 [==============================] - 0s 675us/step - loss: 0.4501 - accuracy: 0.8047\n",
      "Epoch 59/100000\n",
      "28/28 [==============================] - 0s 659us/step - loss: 0.4493 - accuracy: 0.8047\n",
      "Epoch 60/100000\n",
      "28/28 [==============================] - 0s 675us/step - loss: 0.4486 - accuracy: 0.8058\n",
      "Epoch 61/100000\n",
      "28/28 [==============================] - 0s 644us/step - loss: 0.4479 - accuracy: 0.8047\n",
      "Epoch 62/100000\n",
      "28/28 [==============================] - 0s 637us/step - loss: 0.4473 - accuracy: 0.8058\n",
      "Epoch 63/100000\n",
      "28/28 [==============================] - 0s 685us/step - loss: 0.4466 - accuracy: 0.8070\n",
      "Epoch 64/100000\n",
      "28/28 [==============================] - 0s 674us/step - loss: 0.4459 - accuracy: 0.8070\n",
      "Epoch 65/100000\n",
      "28/28 [==============================] - 0s 670us/step - loss: 0.4454 - accuracy: 0.8070\n",
      "Epoch 66/100000\n",
      "28/28 [==============================] - 0s 640us/step - loss: 0.4448 - accuracy: 0.8092\n",
      "Epoch 67/100000\n",
      "28/28 [==============================] - 0s 649us/step - loss: 0.4441 - accuracy: 0.8092\n",
      "Epoch 68/100000\n",
      "28/28 [==============================] - 0s 640us/step - loss: 0.4438 - accuracy: 0.8114\n",
      "Epoch 69/100000\n",
      "28/28 [==============================] - 0s 721us/step - loss: 0.4429 - accuracy: 0.8081\n",
      "Epoch 70/100000\n",
      "28/28 [==============================] - 0s 646us/step - loss: 0.4425 - accuracy: 0.8081\n",
      "Epoch 71/100000\n",
      "28/28 [==============================] - 0s 635us/step - loss: 0.4420 - accuracy: 0.8070\n",
      "Epoch 72/100000\n",
      "28/28 [==============================] - 0s 667us/step - loss: 0.4414 - accuracy: 0.8081\n",
      "Epoch 73/100000\n",
      "28/28 [==============================] - 0s 780us/step - loss: 0.4409 - accuracy: 0.8092\n",
      "Epoch 74/100000\n",
      "28/28 [==============================] - 0s 726us/step - loss: 0.4404 - accuracy: 0.8081\n",
      "Epoch 75/100000\n",
      "28/28 [==============================] - 0s 686us/step - loss: 0.4398 - accuracy: 0.8081\n",
      "Epoch 76/100000\n",
      "28/28 [==============================] - 0s 687us/step - loss: 0.4394 - accuracy: 0.8070\n",
      "Epoch 77/100000\n",
      "28/28 [==============================] - 0s 660us/step - loss: 0.4388 - accuracy: 0.8081\n",
      "Epoch 78/100000\n",
      "28/28 [==============================] - 0s 639us/step - loss: 0.4384 - accuracy: 0.8126\n",
      "Epoch 79/100000\n",
      "28/28 [==============================] - 0s 644us/step - loss: 0.4380 - accuracy: 0.8114\n",
      "Epoch 80/100000\n",
      "28/28 [==============================] - 0s 655us/step - loss: 0.4376 - accuracy: 0.8114\n",
      "Epoch 81/100000\n",
      "28/28 [==============================] - 0s 709us/step - loss: 0.4370 - accuracy: 0.8114\n",
      "Epoch 82/100000\n",
      "28/28 [==============================] - 0s 647us/step - loss: 0.4366 - accuracy: 0.8103\n",
      "Epoch 83/100000\n",
      "28/28 [==============================] - 0s 649us/step - loss: 0.4362 - accuracy: 0.8081\n",
      "Epoch 84/100000\n",
      "28/28 [==============================] - 0s 670us/step - loss: 0.4357 - accuracy: 0.8081\n",
      "Epoch 85/100000\n",
      "28/28 [==============================] - 0s 697us/step - loss: 0.4353 - accuracy: 0.8081\n",
      "Epoch 86/100000\n",
      "28/28 [==============================] - 0s 650us/step - loss: 0.4350 - accuracy: 0.8092\n",
      "Epoch 87/100000\n",
      "28/28 [==============================] - 0s 640us/step - loss: 0.4348 - accuracy: 0.8081\n",
      "Epoch 88/100000\n",
      "28/28 [==============================] - 0s 642us/step - loss: 0.4341 - accuracy: 0.8092\n",
      "Epoch 89/100000\n",
      "28/28 [==============================] - 0s 624us/step - loss: 0.4339 - accuracy: 0.8092\n",
      "Epoch 90/100000\n",
      "28/28 [==============================] - 0s 720us/step - loss: 0.4334 - accuracy: 0.8081\n",
      "Epoch 91/100000\n",
      "28/28 [==============================] - 0s 674us/step - loss: 0.4330 - accuracy: 0.8081\n",
      "Epoch 92/100000\n",
      "28/28 [==============================] - 0s 664us/step - loss: 0.4328 - accuracy: 0.8070\n",
      "Epoch 93/100000\n",
      "28/28 [==============================] - 0s 655us/step - loss: 0.4323 - accuracy: 0.8070\n",
      "Epoch 94/100000\n",
      "28/28 [==============================] - 0s 655us/step - loss: 0.4319 - accuracy: 0.8058\n",
      "Epoch 95/100000\n",
      "28/28 [==============================] - 0s 662us/step - loss: 0.4316 - accuracy: 0.8070\n",
      "Epoch 96/100000\n",
      "28/28 [==============================] - 0s 668us/step - loss: 0.4314 - accuracy: 0.8070\n",
      "Epoch 97/100000\n",
      "28/28 [==============================] - 0s 646us/step - loss: 0.4310 - accuracy: 0.8092\n",
      "Epoch 98/100000\n",
      "28/28 [==============================] - 0s 631us/step - loss: 0.4305 - accuracy: 0.8070\n",
      "Epoch 99/100000\n",
      "28/28 [==============================] - 0s 657us/step - loss: 0.4303 - accuracy: 0.8081\n",
      "Epoch 100/100000\n",
      "28/28 [==============================] - 0s 691us/step - loss: 0.4298 - accuracy: 0.8092\n",
      "Epoch 101/100000\n",
      "28/28 [==============================] - 0s 646us/step - loss: 0.4297 - accuracy: 0.8114\n",
      "Epoch 102/100000\n",
      "28/28 [==============================] - 0s 639us/step - loss: 0.4293 - accuracy: 0.8114\n",
      "Epoch 103/100000\n",
      "28/28 [==============================] - 0s 682us/step - loss: 0.4289 - accuracy: 0.8114\n",
      "Epoch 104/100000\n",
      "28/28 [==============================] - 0s 699us/step - loss: 0.4286 - accuracy: 0.8114\n",
      "Epoch 105/100000\n",
      "28/28 [==============================] - 0s 727us/step - loss: 0.4282 - accuracy: 0.8114\n",
      "Epoch 106/100000\n",
      "28/28 [==============================] - 0s 636us/step - loss: 0.4280 - accuracy: 0.8126\n",
      "Epoch 107/100000\n",
      "28/28 [==============================] - 0s 692us/step - loss: 0.4277 - accuracy: 0.8148\n",
      "Epoch 108/100000\n",
      "28/28 [==============================] - 0s 660us/step - loss: 0.4274 - accuracy: 0.8126\n",
      "Epoch 109/100000\n",
      "28/28 [==============================] - 0s 696us/step - loss: 0.4271 - accuracy: 0.8148\n",
      "Epoch 110/100000\n",
      "28/28 [==============================] - 0s 643us/step - loss: 0.4268 - accuracy: 0.8148\n",
      "Epoch 111/100000\n",
      "28/28 [==============================] - 0s 634us/step - loss: 0.4266 - accuracy: 0.8137\n",
      "Epoch 112/100000\n",
      "28/28 [==============================] - 0s 636us/step - loss: 0.4262 - accuracy: 0.8148\n",
      "Epoch 113/100000\n",
      "28/28 [==============================] - 0s 703us/step - loss: 0.4258 - accuracy: 0.8171\n",
      "Epoch 114/100000\n",
      "28/28 [==============================] - 0s 659us/step - loss: 0.4254 - accuracy: 0.8159\n",
      "Epoch 115/100000\n",
      "28/28 [==============================] - 0s 630us/step - loss: 0.4252 - accuracy: 0.8159\n",
      "Epoch 116/100000\n",
      "28/28 [==============================] - 0s 639us/step - loss: 0.4249 - accuracy: 0.8137\n",
      "Epoch 117/100000\n",
      "28/28 [==============================] - 0s 623us/step - loss: 0.4247 - accuracy: 0.8171\n",
      "Epoch 118/100000\n",
      "28/28 [==============================] - 0s 670us/step - loss: 0.4244 - accuracy: 0.8159\n",
      "Epoch 119/100000\n",
      "28/28 [==============================] - 0s 681us/step - loss: 0.4242 - accuracy: 0.8193\n",
      "Epoch 120/100000\n",
      "28/28 [==============================] - 0s 631us/step - loss: 0.4238 - accuracy: 0.8148\n",
      "Epoch 121/100000\n",
      "28/28 [==============================] - 0s 655us/step - loss: 0.4236 - accuracy: 0.8193\n",
      "Epoch 122/100000\n",
      "28/28 [==============================] - 0s 669us/step - loss: 0.4232 - accuracy: 0.8182\n",
      "Epoch 123/100000\n",
      "28/28 [==============================] - 0s 724us/step - loss: 0.4230 - accuracy: 0.8182\n",
      "Epoch 124/100000\n",
      "28/28 [==============================] - 0s 652us/step - loss: 0.4228 - accuracy: 0.8182\n",
      "Epoch 125/100000\n",
      "28/28 [==============================] - 0s 637us/step - loss: 0.4224 - accuracy: 0.8204\n",
      "Epoch 126/100000\n",
      "28/28 [==============================] - 0s 652us/step - loss: 0.4222 - accuracy: 0.8193\n",
      "Epoch 127/100000\n",
      "28/28 [==============================] - 0s 659us/step - loss: 0.4220 - accuracy: 0.8182\n",
      "Epoch 128/100000\n",
      "28/28 [==============================] - 0s 660us/step - loss: 0.4216 - accuracy: 0.8193\n",
      "Epoch 129/100000\n",
      "28/28 [==============================] - 0s 639us/step - loss: 0.4212 - accuracy: 0.8204\n",
      "Epoch 130/100000\n",
      "28/28 [==============================] - 0s 678us/step - loss: 0.4209 - accuracy: 0.8204\n",
      "Epoch 131/100000\n",
      "28/28 [==============================] - 0s 640us/step - loss: 0.4205 - accuracy: 0.8193\n",
      "Epoch 132/100000\n",
      "28/28 [==============================] - 0s 747us/step - loss: 0.4201 - accuracy: 0.8193\n",
      "Epoch 133/100000\n",
      "28/28 [==============================] - 0s 684us/step - loss: 0.4198 - accuracy: 0.8182\n",
      "Epoch 134/100000\n",
      "28/28 [==============================] - 0s 660us/step - loss: 0.4194 - accuracy: 0.8193\n",
      "Epoch 135/100000\n",
      "28/28 [==============================] - 0s 713us/step - loss: 0.4190 - accuracy: 0.8193\n",
      "Epoch 136/100000\n",
      "28/28 [==============================] - 0s 726us/step - loss: 0.4187 - accuracy: 0.8204\n",
      "Epoch 137/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8204\n",
      "Epoch 138/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8215\n",
      "Epoch 139/100000\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.4177 - accuracy: 0.8227\n",
      "Epoch 140/100000\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.4173 - accuracy: 0.8215\n",
      "Epoch 141/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8227\n",
      "Epoch 142/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8238\n",
      "Epoch 143/100000\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.4163 - accuracy: 0.8238\n",
      "Epoch 144/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8238\n",
      "Epoch 145/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8238\n",
      "Epoch 146/100000\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.4154 - accuracy: 0.8249\n",
      "Epoch 147/100000\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.4152 - accuracy: 0.8238\n",
      "Epoch 148/100000\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.4148 - accuracy: 0.8238\n",
      "Epoch 149/100000\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.4145 - accuracy: 0.8238\n",
      "Epoch 150/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8238\n",
      "Epoch 151/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8272\n",
      "Epoch 152/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8238\n",
      "Epoch 153/100000\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.4132 - accuracy: 0.8238\n",
      "Epoch 154/100000\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.4130 - accuracy: 0.8238\n",
      "Epoch 155/100000\n",
      "28/28 [==============================] - 0s 727us/step - loss: 0.4127 - accuracy: 0.8238\n",
      "Epoch 156/100000\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.4124 - accuracy: 0.8227\n",
      "Epoch 157/100000\n",
      "28/28 [==============================] - 0s 812us/step - loss: 0.4121 - accuracy: 0.8227\n",
      "Epoch 158/100000\n",
      "28/28 [==============================] - 0s 780us/step - loss: 0.4118 - accuracy: 0.8227\n",
      "Epoch 159/100000\n",
      "28/28 [==============================] - 0s 798us/step - loss: 0.4116 - accuracy: 0.8227\n",
      "Epoch 160/100000\n",
      "28/28 [==============================] - 0s 806us/step - loss: 0.4113 - accuracy: 0.8238\n",
      "Epoch 161/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8238\n",
      "Epoch 162/100000\n",
      "28/28 [==============================] - 0s 751us/step - loss: 0.4108 - accuracy: 0.8227\n",
      "Epoch 163/100000\n",
      "28/28 [==============================] - 0s 802us/step - loss: 0.4105 - accuracy: 0.8227\n",
      "Epoch 164/100000\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.4105 - accuracy: 0.8249\n",
      "Epoch 165/100000\n",
      "28/28 [==============================] - 0s 816us/step - loss: 0.4103 - accuracy: 0.8238\n",
      "Epoch 166/100000\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.4099 - accuracy: 0.8238\n",
      "Epoch 167/100000\n",
      "28/28 [==============================] - 0s 770us/step - loss: 0.4096 - accuracy: 0.8238\n",
      "Epoch 168/100000\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.4094 - accuracy: 0.8238\n",
      "Epoch 169/100000\n",
      "28/28 [==============================] - 0s 755us/step - loss: 0.4091 - accuracy: 0.8238\n",
      "Epoch 170/100000\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.4088 - accuracy: 0.8238\n",
      "Epoch 171/100000\n",
      "28/28 [==============================] - 0s 705us/step - loss: 0.4087 - accuracy: 0.8238\n",
      "Epoch 172/100000\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.4085 - accuracy: 0.8238\n",
      "Epoch 173/100000\n",
      "28/28 [==============================] - 0s 751us/step - loss: 0.4084 - accuracy: 0.8238\n",
      "Epoch 174/100000\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.4082 - accuracy: 0.8249\n",
      "Epoch 175/100000\n",
      "28/28 [==============================] - 0s 771us/step - loss: 0.4078 - accuracy: 0.8238\n",
      "Epoch 176/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8238\n",
      "Epoch 177/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.8249\n",
      "Epoch 178/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8238\n",
      "Epoch 179/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8249\n",
      "Epoch 180/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4067 - accuracy: 0.8249\n",
      "Epoch 181/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.8249\n",
      "Epoch 182/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8260\n",
      "Epoch 183/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8249\n",
      "Epoch 184/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4061 - accuracy: 0.8249\n",
      "Epoch 185/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4059 - accuracy: 0.8260\n",
      "Epoch 186/100000\n",
      "28/28 [==============================] - 0s 792us/step - loss: 0.4056 - accuracy: 0.8249\n",
      "Epoch 187/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8249\n",
      "Epoch 188/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4054 - accuracy: 0.8249\n",
      "Epoch 189/100000\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.4051 - accuracy: 0.8249\n",
      "Epoch 190/100000\n",
      "28/28 [==============================] - 0s 809us/step - loss: 0.4050 - accuracy: 0.8249\n",
      "Epoch 191/100000\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.4048 - accuracy: 0.8249\n",
      "Epoch 192/100000\n",
      "28/28 [==============================] - 0s 806us/step - loss: 0.4046 - accuracy: 0.8249\n",
      "Epoch 193/100000\n",
      "28/28 [==============================] - 0s 761us/step - loss: 0.4045 - accuracy: 0.8260\n",
      "Epoch 194/100000\n",
      "28/28 [==============================] - 0s 771us/step - loss: 0.4042 - accuracy: 0.8249\n",
      "Epoch 195/100000\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.4041 - accuracy: 0.8249\n",
      "Epoch 196/100000\n",
      "28/28 [==============================] - 0s 804us/step - loss: 0.4038 - accuracy: 0.8249\n",
      "Epoch 197/100000\n",
      "28/28 [==============================] - 0s 802us/step - loss: 0.4040 - accuracy: 0.8249\n",
      "Epoch 198/100000\n",
      "28/28 [==============================] - 0s 782us/step - loss: 0.4037 - accuracy: 0.8249\n",
      "Epoch 199/100000\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.4035 - accuracy: 0.8260\n",
      "Epoch 200/100000\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.4034 - accuracy: 0.8272\n",
      "Epoch 201/100000\n",
      "28/28 [==============================] - 0s 785us/step - loss: 0.4031 - accuracy: 0.8249\n",
      "Epoch 202/100000\n",
      "28/28 [==============================] - 0s 809us/step - loss: 0.4029 - accuracy: 0.8260\n",
      "Epoch 203/100000\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.4028 - accuracy: 0.8260\n",
      "Epoch 204/100000\n",
      "28/28 [==============================] - 0s 814us/step - loss: 0.4026 - accuracy: 0.8260\n",
      "Epoch 205/100000\n",
      "28/28 [==============================] - 0s 799us/step - loss: 0.4024 - accuracy: 0.8249\n",
      "Epoch 206/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8260\n",
      "Epoch 207/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8260\n",
      "Epoch 208/100000\n",
      "28/28 [==============================] - 0s 781us/step - loss: 0.4020 - accuracy: 0.8294\n",
      "Epoch 209/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4017 - accuracy: 0.8260\n",
      "Epoch 210/100000\n",
      "28/28 [==============================] - 0s 807us/step - loss: 0.4016 - accuracy: 0.8283\n",
      "Epoch 211/100000\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.4015 - accuracy: 0.8283\n",
      "Epoch 212/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8283\n",
      "Epoch 213/100000\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.4012 - accuracy: 0.8283\n",
      "Epoch 214/100000\n",
      "28/28 [==============================] - 0s 786us/step - loss: 0.4010 - accuracy: 0.8294\n",
      "Epoch 215/100000\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.4008 - accuracy: 0.8283\n",
      "Epoch 216/100000\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.4008 - accuracy: 0.8272\n",
      "Epoch 217/100000\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.4005 - accuracy: 0.8294\n",
      "Epoch 218/100000\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.4004 - accuracy: 0.8294\n",
      "Epoch 219/100000\n",
      "28/28 [==============================] - 0s 739us/step - loss: 0.4003 - accuracy: 0.8305\n",
      "Epoch 220/100000\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.4001 - accuracy: 0.8283\n",
      "Epoch 221/100000\n",
      "28/28 [==============================] - 0s 814us/step - loss: 0.3999 - accuracy: 0.8316\n",
      "Epoch 222/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8316\n",
      "Epoch 223/100000\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.3997 - accuracy: 0.8328\n",
      "Epoch 224/100000\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.3995 - accuracy: 0.8316\n",
      "Epoch 225/100000\n",
      "28/28 [==============================] - 0s 767us/step - loss: 0.3994 - accuracy: 0.8328\n",
      "Epoch 226/100000\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.3993 - accuracy: 0.8339\n",
      "Epoch 227/100000\n",
      "28/28 [==============================] - 0s 784us/step - loss: 0.3991 - accuracy: 0.8339\n",
      "Epoch 228/100000\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.3990 - accuracy: 0.8328\n",
      "Epoch 229/100000\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.3989 - accuracy: 0.8328\n",
      "Epoch 230/100000\n",
      "28/28 [==============================] - 0s 750us/step - loss: 0.3987 - accuracy: 0.8328\n",
      "Epoch 231/100000\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.3985 - accuracy: 0.8328\n",
      "Epoch 232/100000\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.3984 - accuracy: 0.8316\n",
      "Epoch 233/100000\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.3982 - accuracy: 0.8328\n",
      "Epoch 234/100000\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.3981 - accuracy: 0.8316\n",
      "Epoch 235/100000\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.3980 - accuracy: 0.8328\n",
      "Epoch 236/100000\n",
      "28/28 [==============================] - 0s 748us/step - loss: 0.3979 - accuracy: 0.8328\n",
      "Epoch 237/100000\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.3977 - accuracy: 0.8328\n",
      "Epoch 238/100000\n",
      "28/28 [==============================] - 0s 691us/step - loss: 0.3975 - accuracy: 0.8328\n",
      "Epoch 239/100000\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.3974 - accuracy: 0.8328\n",
      "Epoch 240/100000\n",
      "28/28 [==============================] - 0s 707us/step - loss: 0.3974 - accuracy: 0.8361\n",
      "Epoch 241/100000\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.3972 - accuracy: 0.8350\n",
      "Epoch 242/100000\n",
      "28/28 [==============================] - 0s 707us/step - loss: 0.3971 - accuracy: 0.8339\n",
      "Epoch 243/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.8305\n",
      "Epoch 244/100000\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.3968 - accuracy: 0.8328\n",
      "Epoch 245/100000\n",
      "28/28 [==============================] - 0s 762us/step - loss: 0.3968 - accuracy: 0.8339\n",
      "Epoch 246/100000\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.3965 - accuracy: 0.8339\n",
      "Epoch 247/100000\n",
      "28/28 [==============================] - 0s 792us/step - loss: 0.3964 - accuracy: 0.8316\n",
      "Epoch 248/100000\n",
      "28/28 [==============================] - 0s 768us/step - loss: 0.3962 - accuracy: 0.8305\n",
      "Epoch 249/100000\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.3962 - accuracy: 0.8328\n",
      "Epoch 250/100000\n",
      "28/28 [==============================] - 0s 743us/step - loss: 0.3960 - accuracy: 0.8305\n",
      "Epoch 251/100000\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.3959 - accuracy: 0.8305\n",
      "Epoch 252/100000\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.3958 - accuracy: 0.8328\n",
      "Epoch 253/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8328\n",
      "Epoch 254/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8328\n",
      "Epoch 255/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8328\n",
      "Epoch 256/100000\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.3953 - accuracy: 0.8328\n",
      "Epoch 257/100000\n",
      "28/28 [==============================] - 0s 803us/step - loss: 0.3951 - accuracy: 0.8316\n",
      "Epoch 258/100000\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.3950 - accuracy: 0.8328\n",
      "Epoch 259/100000\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.3949 - accuracy: 0.8339\n",
      "Epoch 260/100000\n",
      "28/28 [==============================] - 0s 775us/step - loss: 0.3951 - accuracy: 0.8350\n",
      "Epoch 261/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8328\n",
      "Epoch 262/100000\n",
      "28/28 [==============================] - 0s 752us/step - loss: 0.3946 - accuracy: 0.8328\n",
      "Epoch 263/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8361\n",
      "Epoch 264/100000\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.3943 - accuracy: 0.8339\n",
      "Epoch 265/100000\n",
      "28/28 [==============================] - 0s 808us/step - loss: 0.3942 - accuracy: 0.8316\n",
      "Epoch 266/100000\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.3940 - accuracy: 0.8361\n",
      "Epoch 267/100000\n",
      "28/28 [==============================] - 0s 722us/step - loss: 0.3940 - accuracy: 0.8339\n",
      "Epoch 268/100000\n",
      "28/28 [==============================] - 0s 805us/step - loss: 0.3940 - accuracy: 0.8361\n",
      "Epoch 269/100000\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.3937 - accuracy: 0.8339\n",
      "Epoch 270/100000\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.3937 - accuracy: 0.8350\n",
      "Epoch 271/100000\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.3936 - accuracy: 0.8339\n",
      "Epoch 272/100000\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.3934 - accuracy: 0.8350\n",
      "Epoch 273/100000\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.3933 - accuracy: 0.8373\n",
      "Epoch 274/100000\n",
      "28/28 [==============================] - 0s 785us/step - loss: 0.3932 - accuracy: 0.8395\n",
      "Epoch 275/100000\n",
      "28/28 [==============================] - 0s 738us/step - loss: 0.3931 - accuracy: 0.8373\n",
      "Epoch 276/100000\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.3931 - accuracy: 0.8361\n",
      "Epoch 277/100000\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.3929 - accuracy: 0.8384\n",
      "Epoch 278/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8373\n",
      "Epoch 279/100000\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.3928 - accuracy: 0.8350\n",
      "Epoch 280/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8395\n",
      "Epoch 281/100000\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.3925 - accuracy: 0.8395\n",
      "Epoch 282/100000\n",
      "28/28 [==============================] - 0s 778us/step - loss: 0.3924 - accuracy: 0.8373\n",
      "Epoch 283/100000\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.3923 - accuracy: 0.8406\n",
      "Epoch 284/100000\n",
      "28/28 [==============================] - 0s 766us/step - loss: 0.3922 - accuracy: 0.8384\n",
      "Epoch 285/100000\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.3920 - accuracy: 0.8395\n",
      "Epoch 286/100000\n",
      "28/28 [==============================] - 0s 771us/step - loss: 0.3920 - accuracy: 0.8395\n",
      "Epoch 287/100000\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.3917 - accuracy: 0.8406\n",
      "Epoch 288/100000\n",
      "28/28 [==============================] - 0s 769us/step - loss: 0.3917 - accuracy: 0.8406\n",
      "Epoch 289/100000\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.3916 - accuracy: 0.8406\n",
      "Epoch 290/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8406\n",
      "Epoch 291/100000\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.3914 - accuracy: 0.8406\n",
      "Epoch 292/100000\n",
      "28/28 [==============================] - 0s 740us/step - loss: 0.3914 - accuracy: 0.8395\n",
      "Epoch 293/100000\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.3913 - accuracy: 0.8418\n",
      "Epoch 294/100000\n",
      "28/28 [==============================] - 0s 742us/step - loss: 0.3911 - accuracy: 0.8384\n",
      "Epoch 295/100000\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.3910 - accuracy: 0.8406\n",
      "Epoch 296/100000\n",
      "28/28 [==============================] - 0s 713us/step - loss: 0.3909 - accuracy: 0.8418\n",
      "Epoch 297/100000\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.3908 - accuracy: 0.8406\n",
      "Epoch 298/100000\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.3908 - accuracy: 0.8395\n",
      "Epoch 299/100000\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.3907 - accuracy: 0.8418\n",
      "Epoch 300/100000\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.3905 - accuracy: 0.8406\n",
      "Epoch 301/100000\n",
      "28/28 [==============================] - 0s 774us/step - loss: 0.3904 - accuracy: 0.8406\n",
      "Epoch 302/100000\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.3905 - accuracy: 0.8384\n",
      "Epoch 303/100000\n",
      "28/28 [==============================] - 0s 758us/step - loss: 0.3904 - accuracy: 0.8418\n",
      "Epoch 304/100000\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.3901 - accuracy: 0.8395\n",
      "Epoch 305/100000\n",
      "28/28 [==============================] - 0s 777us/step - loss: 0.3899 - accuracy: 0.8384\n",
      "Epoch 306/100000\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.3899 - accuracy: 0.8384\n",
      "Epoch 307/100000\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.3897 - accuracy: 0.8384\n",
      "Epoch 308/100000\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.3897 - accuracy: 0.8406\n",
      "Epoch 309/100000\n",
      "28/28 [==============================] - 0s 794us/step - loss: 0.3896 - accuracy: 0.8395\n",
      "Epoch 310/100000\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.3894 - accuracy: 0.8406\n",
      "Epoch 311/100000\n",
      "28/28 [==============================] - 0s 753us/step - loss: 0.3895 - accuracy: 0.8429\n",
      "Epoch 312/100000\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.3892 - accuracy: 0.8406\n",
      "Epoch 313/100000\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.3892 - accuracy: 0.8429\n",
      "Epoch 314/100000\n",
      "28/28 [==============================] - 0s 798us/step - loss: 0.3890 - accuracy: 0.8429\n",
      "Epoch 315/100000\n",
      "28/28 [==============================] - 0s 797us/step - loss: 0.3889 - accuracy: 0.8429\n",
      "Epoch 316/100000\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.3890 - accuracy: 0.8429\n",
      "Epoch 317/100000\n",
      "28/28 [==============================] - 0s 797us/step - loss: 0.3887 - accuracy: 0.8418\n",
      "Epoch 318/100000\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.3886 - accuracy: 0.8429\n",
      "Epoch 319/100000\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.3884 - accuracy: 0.8418\n",
      "Epoch 320/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8429\n",
      "Epoch 321/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.8429\n",
      "Epoch 322/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3882 - accuracy: 0.8429\n",
      "Epoch 323/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3882 - accuracy: 0.8429\n",
      "Epoch 324/100000\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.3880 - accuracy: 0.8429\n",
      "Epoch 325/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8429\n",
      "Epoch 326/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8429\n",
      "Epoch 327/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8429\n",
      "Epoch 328/100000\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.3876 - accuracy: 0.8429\n",
      "Epoch 329/100000\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.3875 - accuracy: 0.8429\n",
      "Epoch 330/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8440\n",
      "Epoch 331/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8429\n",
      "Epoch 332/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8429\n",
      "Epoch 333/100000\n",
      "28/28 [==============================] - 0s 809us/step - loss: 0.3872 - accuracy: 0.8429\n",
      "Epoch 334/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.8429\n",
      "Epoch 335/100000\n",
      "28/28 [==============================] - 0s 751us/step - loss: 0.3871 - accuracy: 0.8429\n",
      "Epoch 336/100000\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.3870 - accuracy: 0.8429\n",
      "Epoch 337/100000\n",
      "28/28 [==============================] - 0s 760us/step - loss: 0.3869 - accuracy: 0.8429\n",
      "Epoch 338/100000\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.3868 - accuracy: 0.8429\n",
      "Epoch 339/100000\n",
      "28/28 [==============================] - 0s 759us/step - loss: 0.3868 - accuracy: 0.8440\n",
      "Epoch 340/100000\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.3865 - accuracy: 0.8429\n",
      "Epoch 341/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8418\n",
      "Epoch 342/100000\n",
      "28/28 [==============================] - 0s 725us/step - loss: 0.3864 - accuracy: 0.8418\n",
      "Epoch 343/100000\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.3863 - accuracy: 0.8429\n",
      "Epoch 344/100000\n",
      "28/28 [==============================] - 0s 773us/step - loss: 0.3861 - accuracy: 0.8440\n",
      "Epoch 345/100000\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.3861 - accuracy: 0.8418\n",
      "Epoch 346/100000\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.3861 - accuracy: 0.8418\n",
      "Epoch 347/100000\n",
      "28/28 [==============================] - 0s 801us/step - loss: 0.3858 - accuracy: 0.8418\n",
      "Epoch 348/100000\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.3858 - accuracy: 0.8451\n",
      "Epoch 349/100000\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.3857 - accuracy: 0.8462\n",
      "Epoch 350/100000\n",
      "28/28 [==============================] - 0s 744us/step - loss: 0.3856 - accuracy: 0.8429\n",
      "Epoch 351/100000\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.3856 - accuracy: 0.8429\n",
      "Epoch 352/100000\n",
      "28/28 [==============================] - 0s 814us/step - loss: 0.3854 - accuracy: 0.8418\n",
      "Epoch 353/100000\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.3853 - accuracy: 0.8429\n",
      "Epoch 354/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8429\n",
      "Epoch 355/100000\n",
      "28/28 [==============================] - 0s 786us/step - loss: 0.3850 - accuracy: 0.8429\n",
      "Epoch 356/100000\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.3849 - accuracy: 0.8429\n",
      "Epoch 357/100000\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.3849 - accuracy: 0.8451\n",
      "Epoch 358/100000\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.3848 - accuracy: 0.8440\n",
      "Epoch 359/100000\n",
      "28/28 [==============================] - 0s 721us/step - loss: 0.3847 - accuracy: 0.8429\n",
      "Epoch 360/100000\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.3847 - accuracy: 0.8440\n",
      "Epoch 361/100000\n",
      "28/28 [==============================] - 0s 738us/step - loss: 0.3844 - accuracy: 0.8462\n",
      "Epoch 362/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8429\n",
      "Epoch 363/100000\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.3842 - accuracy: 0.8451\n",
      "Epoch 364/100000\n",
      "28/28 [==============================] - 0s 798us/step - loss: 0.3841 - accuracy: 0.8451\n",
      "Epoch 365/100000\n",
      "28/28 [==============================] - 0s 743us/step - loss: 0.3841 - accuracy: 0.8462\n",
      "Epoch 366/100000\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.3840 - accuracy: 0.8440\n",
      "Epoch 367/100000\n",
      "28/28 [==============================] - 0s 769us/step - loss: 0.3839 - accuracy: 0.8474\n",
      "Epoch 368/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8451\n",
      "Epoch 369/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8462\n",
      "Epoch 370/100000\n",
      "28/28 [==============================] - 0s 798us/step - loss: 0.3836 - accuracy: 0.8462\n",
      "Epoch 371/100000\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.3837 - accuracy: 0.8462\n",
      "Epoch 372/100000\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.3835 - accuracy: 0.8474\n",
      "Epoch 373/100000\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.3835 - accuracy: 0.8462\n",
      "Epoch 374/100000\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.3832 - accuracy: 0.8451\n",
      "Epoch 375/100000\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.3830 - accuracy: 0.8462\n",
      "Epoch 376/100000\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.3829 - accuracy: 0.8474\n",
      "Epoch 377/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3829 - accuracy: 0.8462\n",
      "Epoch 378/100000\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.3828 - accuracy: 0.8462\n",
      "Epoch 379/100000\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.3830 - accuracy: 0.8462\n",
      "Epoch 380/100000\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.3826 - accuracy: 0.8474\n",
      "Epoch 381/100000\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.3825 - accuracy: 0.8451\n",
      "Epoch 382/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3828 - accuracy: 0.8474\n",
      "Epoch 383/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8474\n",
      "Epoch 384/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8485\n",
      "Epoch 385/100000\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.3822 - accuracy: 0.8451\n",
      "Epoch 386/100000\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.3820 - accuracy: 0.8462\n",
      "Epoch 387/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3819 - accuracy: 0.8474\n",
      "Epoch 388/100000\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.3818 - accuracy: 0.8474\n",
      "Epoch 389/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3817 - accuracy: 0.8474\n",
      "Epoch 390/100000\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.3817 - accuracy: 0.8474\n",
      "Epoch 391/100000\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.3816 - accuracy: 0.8485\n",
      "Epoch 392/100000\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.3815 - accuracy: 0.8462\n",
      "Epoch 393/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8474\n",
      "Epoch 394/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8451\n",
      "Epoch 395/100000\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.3812 - accuracy: 0.8485\n",
      "Epoch 396/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.8474\n",
      "Epoch 397/100000\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.3810 - accuracy: 0.8485\n",
      "Epoch 398/100000\n",
      "28/28 [==============================] - 0s 706us/step - loss: 0.3810 - accuracy: 0.8474\n",
      "Epoch 399/100000\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.3808 - accuracy: 0.8485\n",
      "Epoch 400/100000\n",
      "28/28 [==============================] - 0s 713us/step - loss: 0.3808 - accuracy: 0.8485\n",
      "Epoch 401/100000\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.3806 - accuracy: 0.8474\n",
      "Epoch 402/100000\n",
      "28/28 [==============================] - 0s 801us/step - loss: 0.3805 - accuracy: 0.8462\n",
      "Epoch 403/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.8485\n",
      "Epoch 404/100000\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.3804 - accuracy: 0.8485\n",
      "Epoch 405/100000\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.3803 - accuracy: 0.8496\n",
      "Epoch 406/100000\n",
      "28/28 [==============================] - 0s 765us/step - loss: 0.3803 - accuracy: 0.8496\n",
      "Epoch 407/100000\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.3801 - accuracy: 0.8496\n",
      "Epoch 408/100000\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.3801 - accuracy: 0.8474\n",
      "Epoch 409/100000\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.3801 - accuracy: 0.8507\n",
      "Epoch 410/100000\n",
      "28/28 [==============================] - 0s 768us/step - loss: 0.3799 - accuracy: 0.8485\n",
      "Epoch 411/100000\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.3798 - accuracy: 0.8485\n",
      "Epoch 412/100000\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.3798 - accuracy: 0.8496\n",
      "Epoch 413/100000\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.3798 - accuracy: 0.8507\n",
      "Epoch 414/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8496\n",
      "Epoch 415/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8485\n",
      "Epoch 416/100000\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.3794 - accuracy: 0.8496\n",
      "Epoch 417/100000\n",
      "28/28 [==============================] - 0s 757us/step - loss: 0.3795 - accuracy: 0.8496\n",
      "Epoch 418/100000\n",
      "28/28 [==============================] - 0s 776us/step - loss: 0.3793 - accuracy: 0.8485\n",
      "Epoch 419/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8496\n",
      "Epoch 420/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8496\n",
      "Epoch 421/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8507\n",
      "Epoch 422/100000\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.3790 - accuracy: 0.8496\n",
      "Epoch 423/100000\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.3789 - accuracy: 0.8496\n",
      "Epoch 424/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8485\n",
      "Epoch 425/100000\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.3788 - accuracy: 0.8496\n",
      "Epoch 426/100000\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.3788 - accuracy: 0.8485\n",
      "Epoch 427/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8474\n",
      "Epoch 428/100000\n",
      "28/28 [==============================] - 0s 811us/step - loss: 0.3785 - accuracy: 0.8496\n",
      "Epoch 429/100000\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.3784 - accuracy: 0.8496\n",
      "Epoch 430/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8507\n",
      "Epoch 431/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8496\n",
      "Epoch 432/100000\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.3782 - accuracy: 0.8496\n",
      "Epoch 433/100000\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.3781 - accuracy: 0.8496\n",
      "Epoch 434/100000\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.3781 - accuracy: 0.8485\n",
      "Epoch 435/100000\n",
      "28/28 [==============================] - 0s 746us/step - loss: 0.3785 - accuracy: 0.8485\n",
      "Epoch 436/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8474\n",
      "Epoch 437/100000\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.3781 - accuracy: 0.8507\n",
      "Epoch 438/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8507\n",
      "Epoch 439/100000\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.3778 - accuracy: 0.8496\n",
      "Epoch 440/100000\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.3779 - accuracy: 0.8496\n",
      "Epoch 441/100000\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.3777 - accuracy: 0.8485\n",
      "Epoch 442/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8496\n",
      "Epoch 443/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8496\n",
      "Epoch 444/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8485\n",
      "Epoch 445/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8474\n",
      "Epoch 446/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8485\n",
      "Epoch 447/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8496\n",
      "Epoch 448/100000\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.3771 - accuracy: 0.8485\n",
      "Epoch 449/100000\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.3770 - accuracy: 0.8496\n",
      "Epoch 450/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8485\n",
      "Epoch 451/100000\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.3769 - accuracy: 0.8485\n",
      "Epoch 452/100000\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.3768 - accuracy: 0.8485\n",
      "Epoch 453/100000\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.3768 - accuracy: 0.8496\n",
      "Epoch 454/100000\n",
      "28/28 [==============================] - 0s 783us/step - loss: 0.3767 - accuracy: 0.8496\n",
      "Epoch 455/100000\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.3767 - accuracy: 0.8496\n",
      "Epoch 456/100000\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.3766 - accuracy: 0.8485\n",
      "Epoch 457/100000\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.3764 - accuracy: 0.8485\n",
      "Epoch 458/100000\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.3765 - accuracy: 0.8474\n",
      "Epoch 459/100000\n",
      "28/28 [==============================] - 0s 770us/step - loss: 0.3765 - accuracy: 0.8485\n",
      "Epoch 460/100000\n",
      "28/28 [==============================] - 0s 793us/step - loss: 0.3762 - accuracy: 0.8485\n",
      "Epoch 461/100000\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.3763 - accuracy: 0.8496\n",
      "Epoch 462/100000\n",
      "28/28 [==============================] - 0s 753us/step - loss: 0.3762 - accuracy: 0.8496\n",
      "Epoch 463/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8485\n",
      "Epoch 464/100000\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.3760 - accuracy: 0.8474\n",
      "Epoch 465/100000\n",
      "28/28 [==============================] - 0s 739us/step - loss: 0.3760 - accuracy: 0.8474\n",
      "Epoch 466/100000\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.3759 - accuracy: 0.8474\n",
      "Epoch 467/100000\n",
      "28/28 [==============================] - 0s 767us/step - loss: 0.3757 - accuracy: 0.8474\n",
      "Epoch 468/100000\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.3758 - accuracy: 0.8485\n",
      "Epoch 469/100000\n",
      "28/28 [==============================] - 0s 787us/step - loss: 0.3756 - accuracy: 0.8485\n",
      "Epoch 470/100000\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.3756 - accuracy: 0.8474\n",
      "Epoch 471/100000\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.3754 - accuracy: 0.8474\n",
      "Epoch 472/100000\n",
      "28/28 [==============================] - 0s 792us/step - loss: 0.3754 - accuracy: 0.8474\n",
      "Epoch 473/100000\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.3753 - accuracy: 0.8485\n",
      "Epoch 474/100000\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.3753 - accuracy: 0.8474\n",
      "Epoch 475/100000\n",
      "28/28 [==============================] - 0s 799us/step - loss: 0.3753 - accuracy: 0.8474\n",
      "Epoch 476/100000\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.3753 - accuracy: 0.8474\n",
      "Epoch 477/100000\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.3751 - accuracy: 0.8474\n",
      "Epoch 478/100000\n",
      "28/28 [==============================] - 0s 791us/step - loss: 0.3750 - accuracy: 0.8485\n",
      "Epoch 479/100000\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.3751 - accuracy: 0.8485\n",
      "Epoch 480/100000\n",
      "28/28 [==============================] - 0s 806us/step - loss: 0.3750 - accuracy: 0.8485\n",
      "Epoch 481/100000\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.3749 - accuracy: 0.8485\n",
      "Epoch 482/100000\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.3748 - accuracy: 0.8485\n",
      "Epoch 483/100000\n",
      "28/28 [==============================] - 0s 788us/step - loss: 0.3748 - accuracy: 0.8474\n",
      "Epoch 484/100000\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.3747 - accuracy: 0.8474\n",
      "Epoch 485/100000\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.3747 - accuracy: 0.8462\n",
      "Epoch 486/100000\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.3745 - accuracy: 0.8474\n",
      "Epoch 487/100000\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.3746 - accuracy: 0.8474\n",
      "Epoch 488/100000\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.3745 - accuracy: 0.8485\n",
      "Epoch 489/100000\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.3745 - accuracy: 0.8474\n",
      "Epoch 490/100000\n",
      "28/28 [==============================] - 0s 764us/step - loss: 0.3744 - accuracy: 0.8474\n",
      "Epoch 491/100000\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.3743 - accuracy: 0.8485\n",
      "Epoch 492/100000\n",
      "28/28 [==============================] - 0s 778us/step - loss: 0.3743 - accuracy: 0.8485\n",
      "Epoch 493/100000\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.3741 - accuracy: 0.8474\n",
      "Epoch 494/100000\n",
      "28/28 [==============================] - 0s 784us/step - loss: 0.3740 - accuracy: 0.8474\n",
      "Epoch 495/100000\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.3740 - accuracy: 0.8474\n",
      "Epoch 496/100000\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.3740 - accuracy: 0.8474\n",
      "Epoch 497/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8462\n",
      "Epoch 498/100000\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.3738 - accuracy: 0.8485\n",
      "Epoch 499/100000\n",
      "28/28 [==============================] - 0s 774us/step - loss: 0.3738 - accuracy: 0.8474\n",
      "Epoch 500/100000\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.3737 - accuracy: 0.8474\n",
      "Epoch 501/100000\n",
      "28/28 [==============================] - 0s 719us/step - loss: 0.3737 - accuracy: 0.8474\n",
      "Epoch 502/100000\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.3736 - accuracy: 0.8474\n",
      "Epoch 503/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8462\n",
      "Epoch 504/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8496\n",
      "Epoch 505/100000\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.3735 - accuracy: 0.8474\n",
      "Epoch 506/100000\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.3734 - accuracy: 0.8485\n",
      "Epoch 507/100000\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.3733 - accuracy: 0.8485\n",
      "Epoch 508/100000\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.3733 - accuracy: 0.8485\n",
      "Epoch 509/100000\n",
      "28/28 [==============================] - 0s 796us/step - loss: 0.3733 - accuracy: 0.8474\n",
      "Epoch 510/100000\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.3732 - accuracy: 0.8496\n",
      "Epoch 511/100000\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.3731 - accuracy: 0.8496\n",
      "Epoch 512/100000\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.3732 - accuracy: 0.8496\n",
      "Epoch 513/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8496\n",
      "Epoch 514/100000\n",
      "28/28 [==============================] - 0s 756us/step - loss: 0.3732 - accuracy: 0.8496\n",
      "Epoch 515/100000\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.3731 - accuracy: 0.8474\n",
      "Epoch 516/100000\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.3728 - accuracy: 0.8474\n",
      "Epoch 517/100000\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.3729 - accuracy: 0.8485\n",
      "Epoch 518/100000\n",
      "28/28 [==============================] - 0s 1000us/step - loss: 0.3729 - accuracy: 0.8485\n",
      "Epoch 519/100000\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.3727 - accuracy: 0.8485\n",
      "Epoch 520/100000\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.3728 - accuracy: 0.8496\n",
      "Epoch 521/100000\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.3728 - accuracy: 0.8496\n",
      "Epoch 522/100000\n",
      "28/28 [==============================] - 0s 772us/step - loss: 0.3726 - accuracy: 0.8496\n",
      "Epoch 523/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8496\n",
      "Epoch 524/100000\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.3726 - accuracy: 0.8485\n",
      "Epoch 525/100000\n",
      "28/28 [==============================] - 0s 768us/step - loss: 0.3725 - accuracy: 0.8474\n",
      "Epoch 526/100000\n",
      "28/28 [==============================] - 0s 765us/step - loss: 0.3725 - accuracy: 0.8496\n",
      "Epoch 527/100000\n",
      "28/28 [==============================] - 0s 807us/step - loss: 0.3724 - accuracy: 0.8485\n",
      "Epoch 528/100000\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.3724 - accuracy: 0.8496\n",
      "Epoch 529/100000\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.3723 - accuracy: 0.8485\n",
      "Epoch 530/100000\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.3722 - accuracy: 0.8485\n",
      "Epoch 531/100000\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.3721 - accuracy: 0.8496\n",
      "Epoch 532/100000\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.3720 - accuracy: 0.8485\n",
      "Epoch 533/100000\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.3722 - accuracy: 0.8485\n",
      "Epoch 534/100000\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.3721 - accuracy: 0.8485\n",
      "Epoch 535/100000\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.3726 - accuracy: 0.8474\n",
      "Epoch 536/100000\n",
      "28/28 [==============================] - 0s 792us/step - loss: 0.3720 - accuracy: 0.8485\n",
      "Epoch 537/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3720 - accuracy: 0.8507\n",
      "Epoch 538/100000\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.3718 - accuracy: 0.8496\n",
      "Epoch 539/100000\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.3720 - accuracy: 0.8485\n",
      "Epoch 540/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8496\n",
      "Epoch 541/100000\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.3717 - accuracy: 0.8496\n",
      "Epoch 542/100000\n",
      "28/28 [==============================] - 0s 816us/step - loss: 0.3716 - accuracy: 0.8485\n",
      "Epoch 543/100000\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.3715 - accuracy: 0.8485\n",
      "Epoch 544/100000\n",
      "28/28 [==============================] - 0s 809us/step - loss: 0.3715 - accuracy: 0.8485\n",
      "Epoch 545/100000\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.3715 - accuracy: 0.8485\n",
      "Epoch 546/100000\n",
      "28/28 [==============================] - 0s 806us/step - loss: 0.3715 - accuracy: 0.8485\n",
      "Epoch 547/100000\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.3714 - accuracy: 0.8496\n",
      "Epoch 548/100000\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.3713 - accuracy: 0.8485\n",
      "Epoch 549/100000\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.3713 - accuracy: 0.8485\n",
      "Epoch 550/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8496\n",
      "Epoch 551/100000\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.3712 - accuracy: 0.8485\n",
      "Epoch 552/100000\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.3713 - accuracy: 0.8496\n",
      "Epoch 553/100000\n",
      "28/28 [==============================] - 0s 740us/step - loss: 0.3712 - accuracy: 0.8485\n",
      "Epoch 554/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8496\n",
      "Epoch 555/100000\n",
      "28/28 [==============================] - 0s 807us/step - loss: 0.3711 - accuracy: 0.8496\n",
      "Epoch 556/100000\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.3709 - accuracy: 0.8485\n",
      "Epoch 557/100000\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.3709 - accuracy: 0.8485\n",
      "Epoch 558/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8507\n",
      "Epoch 559/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8485\n",
      "Epoch 560/100000\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.3707 - accuracy: 0.8496\n",
      "Epoch 561/100000\n",
      "28/28 [==============================] - 0s 796us/step - loss: 0.3708 - accuracy: 0.8496\n",
      "Epoch 562/100000\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.3706 - accuracy: 0.8496\n",
      "Epoch 563/100000\n",
      "28/28 [==============================] - 0s 784us/step - loss: 0.3707 - accuracy: 0.8485\n",
      "Epoch 564/100000\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.3706 - accuracy: 0.8496\n",
      "Epoch 565/100000\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.3706 - accuracy: 0.8485\n",
      "Epoch 566/100000\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.3706 - accuracy: 0.8507\n",
      "Epoch 567/100000\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.3705 - accuracy: 0.8474\n",
      "Epoch 568/100000\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.3706 - accuracy: 0.8485\n",
      "Epoch 569/100000\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.3704 - accuracy: 0.8496\n",
      "Epoch 570/100000\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.3703 - accuracy: 0.8485\n",
      "Epoch 571/100000\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.3704 - accuracy: 0.8485\n",
      "Epoch 572/100000\n",
      "28/28 [==============================] - 0s 766us/step - loss: 0.3703 - accuracy: 0.8485\n",
      "Epoch 573/100000\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.3702 - accuracy: 0.8496\n",
      "Epoch 574/100000\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.3702 - accuracy: 0.8485\n",
      "Epoch 575/100000\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.3702 - accuracy: 0.8496\n",
      "Epoch 576/100000\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.3702 - accuracy: 0.8462\n",
      "Epoch 577/100000\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.3700 - accuracy: 0.8485\n",
      "Epoch 578/100000\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.3699 - accuracy: 0.8507\n",
      "Epoch 579/100000\n",
      "28/28 [==============================] - 0s 798us/step - loss: 0.3699 - accuracy: 0.8485\n",
      "Epoch 580/100000\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.3700 - accuracy: 0.8462\n",
      "Epoch 581/100000\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.3700 - accuracy: 0.8474\n",
      "Epoch 582/100000\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.3698 - accuracy: 0.8462\n",
      "Epoch 583/100000\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.3698 - accuracy: 0.8474\n",
      "Epoch 584/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8496\n",
      "Epoch 585/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8485\n",
      "Epoch 586/100000\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.3696 - accuracy: 0.8462\n",
      "Epoch 587/100000\n",
      "28/28 [==============================] - 0s 812us/step - loss: 0.3695 - accuracy: 0.8485\n",
      "Epoch 588/100000\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.3696 - accuracy: 0.8485\n",
      "Epoch 589/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8485\n",
      "Epoch 590/100000\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.3695 - accuracy: 0.8474\n",
      "Epoch 591/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8485\n",
      "Epoch 592/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8485\n",
      "Epoch 593/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3693 - accuracy: 0.8485\n",
      "Epoch 594/100000\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.3692 - accuracy: 0.8485\n",
      "Epoch 595/100000\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.3694 - accuracy: 0.8485\n",
      "Epoch 596/100000\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.3692 - accuracy: 0.8462\n",
      "Epoch 597/100000\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.3692 - accuracy: 0.8485\n",
      "Epoch 598/100000\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.3691 - accuracy: 0.8462\n",
      "Epoch 599/100000\n",
      "28/28 [==============================] - 0s 790us/step - loss: 0.3690 - accuracy: 0.8485\n",
      "Epoch 600/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8496\n",
      "Epoch 601/100000\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.3689 - accuracy: 0.8474\n",
      "Epoch 602/100000\n",
      "28/28 [==============================] - 0s 779us/step - loss: 0.3689 - accuracy: 0.8485\n",
      "Epoch 603/100000\n",
      "28/28 [==============================] - 0s 812us/step - loss: 0.3688 - accuracy: 0.8474\n",
      "Epoch 604/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3689 - accuracy: 0.8474\n",
      "Epoch 605/100000\n",
      "28/28 [==============================] - 0s 774us/step - loss: 0.3688 - accuracy: 0.8485\n",
      "Epoch 606/100000\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.3687 - accuracy: 0.8485\n",
      "Epoch 607/100000\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.3686 - accuracy: 0.8485\n",
      "Epoch 608/100000\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.3688 - accuracy: 0.8485\n",
      "Epoch 609/100000\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.3686 - accuracy: 0.8507\n",
      "Epoch 610/100000\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.3685 - accuracy: 0.8496\n",
      "Epoch 611/100000\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.3686 - accuracy: 0.8496\n",
      "Epoch 612/100000\n",
      "28/28 [==============================] - 0s 790us/step - loss: 0.3685 - accuracy: 0.8496\n",
      "Epoch 613/100000\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.3684 - accuracy: 0.8496\n",
      "Epoch 614/100000\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.3684 - accuracy: 0.8530\n",
      "Epoch 615/100000\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.3684 - accuracy: 0.8507\n",
      "Epoch 616/100000\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.3683 - accuracy: 0.8507\n",
      "Epoch 617/100000\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.3683 - accuracy: 0.8519\n",
      "Epoch 618/100000\n",
      "28/28 [==============================] - 0s 799us/step - loss: 0.3683 - accuracy: 0.8519\n",
      "Epoch 619/100000\n",
      "28/28 [==============================] - 0s 778us/step - loss: 0.3682 - accuracy: 0.8519\n",
      "Epoch 620/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8519\n",
      "Epoch 621/100000\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.3682 - accuracy: 0.8519\n",
      "Epoch 622/100000\n",
      "28/28 [==============================] - 0s 796us/step - loss: 0.3680 - accuracy: 0.8519\n",
      "Epoch 623/100000\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.3679 - accuracy: 0.8519\n",
      "Epoch 624/100000\n",
      "28/28 [==============================] - 0s 805us/step - loss: 0.3679 - accuracy: 0.8541\n",
      "Epoch 625/100000\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.3679 - accuracy: 0.8519\n",
      "Epoch 626/100000\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.3678 - accuracy: 0.8541\n",
      "Epoch 627/100000\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.3678 - accuracy: 0.8530\n",
      "Epoch 628/100000\n",
      "28/28 [==============================] - 0s 745us/step - loss: 0.3677 - accuracy: 0.8530\n",
      "Epoch 629/100000\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.3679 - accuracy: 0.8519\n",
      "Epoch 630/100000\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.3677 - accuracy: 0.8541\n",
      "Epoch 631/100000\n",
      "28/28 [==============================] - 0s 809us/step - loss: 0.3678 - accuracy: 0.8541\n",
      "Epoch 632/100000\n",
      "28/28 [==============================] - 0s 801us/step - loss: 0.3677 - accuracy: 0.8541\n",
      "Epoch 633/100000\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.3676 - accuracy: 0.8541\n",
      "Epoch 634/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8541\n",
      "Epoch 635/100000\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.3675 - accuracy: 0.8541\n",
      "Epoch 636/100000\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.3675 - accuracy: 0.8541\n",
      "Epoch 637/100000\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.3675 - accuracy: 0.8541\n",
      "Epoch 638/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8541\n",
      "Epoch 639/100000\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.3674 - accuracy: 0.8541\n",
      "Epoch 640/100000\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.3673 - accuracy: 0.8541\n",
      "Epoch 641/100000\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.3675 - accuracy: 0.8541\n",
      "Epoch 642/100000\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.3672 - accuracy: 0.8541\n",
      "Epoch 643/100000\n",
      "28/28 [==============================] - 0s 780us/step - loss: 0.3672 - accuracy: 0.8541\n",
      "Epoch 644/100000\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.3671 - accuracy: 0.8541\n",
      "Epoch 645/100000\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.3672 - accuracy: 0.8541\n",
      "Epoch 646/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8541\n",
      "Epoch 647/100000\n",
      "28/28 [==============================] - 0s 743us/step - loss: 0.3670 - accuracy: 0.8552\n",
      "Epoch 648/100000\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.3671 - accuracy: 0.8530\n",
      "Epoch 649/100000\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.3670 - accuracy: 0.8541\n",
      "Epoch 650/100000\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.3670 - accuracy: 0.8541\n",
      "Epoch 651/100000\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.3669 - accuracy: 0.8541\n",
      "Epoch 652/100000\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.3669 - accuracy: 0.8541\n",
      "Epoch 653/100000\n",
      "28/28 [==============================] - 0s 810us/step - loss: 0.3668 - accuracy: 0.8541\n",
      "Epoch 654/100000\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.3667 - accuracy: 0.8541\n",
      "Epoch 655/100000\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.3668 - accuracy: 0.8541\n",
      "Epoch 656/100000\n",
      "28/28 [==============================] - 0s 740us/step - loss: 0.3668 - accuracy: 0.8575\n",
      "Epoch 657/100000\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.3667 - accuracy: 0.8519\n",
      "Epoch 658/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8530\n",
      "Epoch 659/100000\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.3667 - accuracy: 0.8519\n",
      "Epoch 660/100000\n",
      "28/28 [==============================] - 0s 757us/step - loss: 0.3666 - accuracy: 0.8530\n",
      "Epoch 661/100000\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.3667 - accuracy: 0.8519\n",
      "Epoch 662/100000\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.3665 - accuracy: 0.8563\n",
      "Epoch 663/100000\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.3666 - accuracy: 0.8519\n",
      "Epoch 664/100000\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.3664 - accuracy: 0.8530\n",
      "Epoch 665/100000\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.3663 - accuracy: 0.8530\n",
      "Epoch 666/100000\n",
      "28/28 [==============================] - 0s 770us/step - loss: 0.3665 - accuracy: 0.8552\n",
      "Epoch 667/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8530\n",
      "Epoch 668/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.8552\n",
      "Epoch 669/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.8552\n",
      "Epoch 670/100000\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.3661 - accuracy: 0.8563\n",
      "Epoch 671/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8563\n",
      "Epoch 672/100000\n",
      "28/28 [==============================] - 0s 792us/step - loss: 0.3660 - accuracy: 0.8563\n",
      "Epoch 673/100000\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.3663 - accuracy: 0.8552\n",
      "Epoch 674/100000\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.3660 - accuracy: 0.8563\n",
      "Epoch 675/100000\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.3659 - accuracy: 0.8552\n",
      "Epoch 676/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3659 - accuracy: 0.8552\n",
      "Epoch 677/100000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8552\n",
      "Epoch 678/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8530\n",
      "Epoch 679/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8541\n",
      "Epoch 680/100000\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.3658 - accuracy: 0.8563\n",
      "Epoch 681/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8563\n",
      "Epoch 682/100000\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.3658 - accuracy: 0.8575\n",
      "Epoch 683/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8552\n",
      "Epoch 684/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8563\n",
      "Epoch 685/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8563\n",
      "Epoch 686/100000\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.3660 - accuracy: 0.8575\n",
      "Epoch 687/100000\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.3656 - accuracy: 0.8530\n",
      "Epoch 688/100000\n",
      "28/28 [==============================] - 0s 797us/step - loss: 0.3654 - accuracy: 0.8541\n",
      "Epoch 689/100000\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.3654 - accuracy: 0.8530\n",
      "Epoch 690/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8563\n",
      "Epoch 691/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8563\n",
      "Epoch 692/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8575\n",
      "Epoch 693/100000\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.3654 - accuracy: 0.8575\n",
      "Epoch 694/100000\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.3653 - accuracy: 0.8575\n",
      "Epoch 695/100000\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.3652 - accuracy: 0.8563\n",
      "Epoch 696/100000\n",
      "28/28 [==============================] - 0s 814us/step - loss: 0.3651 - accuracy: 0.8563\n",
      "Epoch 697/100000\n",
      "28/28 [==============================] - 0s 786us/step - loss: 0.3651 - accuracy: 0.8563\n",
      "Epoch 698/100000\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.3651 - accuracy: 0.8563\n",
      "Epoch 699/100000\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.3654 - accuracy: 0.8563\n",
      "Epoch 700/100000\n",
      "28/28 [==============================] - 0s 752us/step - loss: 0.3650 - accuracy: 0.8563\n",
      "Epoch 701/100000\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.3649 - accuracy: 0.8563\n",
      "Epoch 702/100000\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.3650 - accuracy: 0.8575\n",
      "Epoch 703/100000\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.3649 - accuracy: 0.8575\n",
      "Epoch 704/100000\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.3649 - accuracy: 0.8575\n",
      "Epoch 705/100000\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.3649 - accuracy: 0.8563\n",
      "Epoch 706/100000\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.3648 - accuracy: 0.8563\n",
      "Epoch 707/100000\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.3648 - accuracy: 0.8575\n",
      "Epoch 708/100000\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.3647 - accuracy: 0.8563\n",
      "Epoch 709/100000\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.3647 - accuracy: 0.8563\n",
      "Epoch 710/100000\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.3646 - accuracy: 0.8586\n",
      "Epoch 711/100000\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.3645 - accuracy: 0.8575\n",
      "Epoch 712/100000\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.3645 - accuracy: 0.8575\n",
      "Epoch 713/100000\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.3645 - accuracy: 0.8586\n",
      "Epoch 714/100000\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.3644 - accuracy: 0.8586\n",
      "Epoch 715/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8575\n",
      "Epoch 716/100000\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.3643 - accuracy: 0.8575\n",
      "Epoch 717/100000\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.3645 - accuracy: 0.8575\n",
      "Epoch 718/100000\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.3645 - accuracy: 0.8575\n",
      "Epoch 719/100000\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.3642 - accuracy: 0.8575\n",
      "Epoch 720/100000\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.3643 - accuracy: 0.8586\n",
      "Epoch 721/100000\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.3644 - accuracy: 0.8575\n",
      "Epoch 722/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8575\n",
      "Epoch 723/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8575\n",
      "Epoch 724/100000\n",
      "28/28 [==============================] - 0s 803us/step - loss: 0.3642 - accuracy: 0.8586\n",
      "Epoch 725/100000\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.3640 - accuracy: 0.8575\n",
      "Epoch 726/100000\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.3641 - accuracy: 0.8575\n",
      "Epoch 727/100000\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.3639 - accuracy: 0.8575\n",
      "Epoch 728/100000\n",
      "28/28 [==============================] - 0s 748us/step - loss: 0.3639 - accuracy: 0.8575\n",
      "Epoch 729/100000\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.3638 - accuracy: 0.8575\n",
      "Epoch 730/100000\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.3639 - accuracy: 0.8575\n",
      "Epoch 731/100000\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.3638 - accuracy: 0.8575\n",
      "Epoch 732/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8575\n",
      "Epoch 733/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8575\n",
      "Epoch 734/100000\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.3638 - accuracy: 0.8575\n",
      "Epoch 735/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8575\n",
      "Epoch 736/100000\n",
      "28/28 [==============================] - 0s 778us/step - loss: 0.3636 - accuracy: 0.8575\n",
      "Epoch 737/100000\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.3636 - accuracy: 0.8575\n",
      "Epoch 738/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8575\n",
      "Epoch 739/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8575\n",
      "Epoch 740/100000\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.3636 - accuracy: 0.8575\n",
      "Epoch 741/100000\n",
      "28/28 [==============================] - 0s 804us/step - loss: 0.3635 - accuracy: 0.8575\n",
      "Epoch 742/100000\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.3636 - accuracy: 0.8575\n",
      "Epoch 743/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8575\n",
      "Epoch 744/100000\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.3634 - accuracy: 0.8575\n",
      "Epoch 745/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8575\n",
      "Epoch 746/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8575\n",
      "Epoch 747/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8575\n",
      "Epoch 748/100000\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.3633 - accuracy: 0.8575\n",
      "Epoch 749/100000\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.3632 - accuracy: 0.8575\n",
      "Epoch 750/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8575\n",
      "Epoch 751/100000\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.3631 - accuracy: 0.8575\n",
      "Epoch 752/100000\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.3631 - accuracy: 0.8575\n",
      "Epoch 753/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8575\n",
      "Epoch 754/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8575\n",
      "Epoch 755/100000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8575\n",
      "Epoch 756/100000\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.3630 - accuracy: 0.8575\n",
      "Epoch 757/100000\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.3629 - accuracy: 0.8575\n",
      "Epoch 758/100000\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.3630 - accuracy: 0.8575\n",
      "Epoch 759/100000\n",
      " 1/28 [>.............................] - ETA: 0s - loss: 0.3657 - accuracy: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75006/2287257641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ai_ml_nn/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai_ml_nn/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai_ml_nn/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai_ml_nn/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai_ml_nn/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai_ml_nn/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai_ml_nn/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai_ml_nn/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/ai_ml_nn/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X,Y,epochs=100000,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=tf.convert_to_tensor(testLM2)\n",
    "Y_pred=model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09308887],\n",
       "       [0.09473667],\n",
       "       [0.09308904],\n",
       "       [0.09308925],\n",
       "       [0.09348464],\n",
       "       [0.09380242],\n",
       "       [0.618506  ],\n",
       "       [0.09310016],\n",
       "       [0.6822389 ],\n",
       "       [0.09308881],\n",
       "       [0.09308925],\n",
       "       [0.43333542],\n",
       "       [1.        ],\n",
       "       [0.09308881],\n",
       "       [1.        ],\n",
       "       [0.94219625],\n",
       "       [0.09309277],\n",
       "       [0.09312305],\n",
       "       [0.1993168 ],\n",
       "       [0.10343316],\n",
       "       [0.31873804],\n",
       "       [0.7408316 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.09308881],\n",
       "       [1.        ],\n",
       "       [0.0930981 ],\n",
       "       [0.47732362],\n",
       "       [0.09308881],\n",
       "       [0.09308994],\n",
       "       [0.09308913],\n",
       "       [0.09310046],\n",
       "       [0.09333009],\n",
       "       [0.62647617],\n",
       "       [0.09324518],\n",
       "       [0.5466235 ],\n",
       "       [0.42721814],\n",
       "       [0.09308994],\n",
       "       [0.09308881],\n",
       "       [0.09308881],\n",
       "       [0.2453162 ],\n",
       "       [0.09308881],\n",
       "       [0.9999852 ],\n",
       "       [1.        ],\n",
       "       [0.09308985],\n",
       "       [0.44565588],\n",
       "       [0.09308925],\n",
       "       [1.        ],\n",
       "       [0.09308991],\n",
       "       [0.18390393],\n",
       "       [0.09308898],\n",
       "       [0.9961251 ],\n",
       "       [1.        ],\n",
       "       [0.09308922],\n",
       "       [0.09308881],\n",
       "       [0.09308887],\n",
       "       [0.09308985],\n",
       "       [0.09308881],\n",
       "       [1.        ],\n",
       "       [0.09336683],\n",
       "       [0.09309006],\n",
       "       [0.09327716],\n",
       "       [0.42715117],\n",
       "       [0.09335193],\n",
       "       [0.9999809 ],\n",
       "       [0.6453518 ],\n",
       "       [0.10495651],\n",
       "       [0.43434015],\n",
       "       [1.        ],\n",
       "       [0.48852628],\n",
       "       [0.09312305],\n",
       "       [0.8031863 ],\n",
       "       [0.5884806 ],\n",
       "       [1.        ],\n",
       "       [0.09308887],\n",
       "       [0.09308925],\n",
       "       [0.9645581 ],\n",
       "       [0.09308913],\n",
       "       [0.48852628],\n",
       "       [1.        ],\n",
       "       [0.09814009],\n",
       "       [0.67443913],\n",
       "       [0.09308925],\n",
       "       [0.0930891 ],\n",
       "       [0.09308881],\n",
       "       [0.8798086 ],\n",
       "       [0.63561964],\n",
       "       [0.5505562 ],\n",
       "       [1.        ],\n",
       "       [0.19465089],\n",
       "       [0.09308925],\n",
       "       [1.        ],\n",
       "       [0.09308925],\n",
       "       [1.        ],\n",
       "       [0.09308985],\n",
       "       [0.9999502 ],\n",
       "       [0.09308931],\n",
       "       [0.5147033 ],\n",
       "       [0.09308895],\n",
       "       [1.        ],\n",
       "       [0.09338889],\n",
       "       [0.09308925],\n",
       "       [0.0930894 ],\n",
       "       [0.09577239],\n",
       "       [0.09309065],\n",
       "       [0.09312305],\n",
       "       [0.09308925],\n",
       "       [0.09308931],\n",
       "       [0.09317192],\n",
       "       [0.09311   ],\n",
       "       [0.55017954],\n",
       "       [1.        ],\n",
       "       [0.6458603 ],\n",
       "       [1.        ],\n",
       "       [0.11287937],\n",
       "       [0.09308925],\n",
       "       [0.99999726],\n",
       "       [0.09308922],\n",
       "       [0.99873495],\n",
       "       [1.        ],\n",
       "       [0.09308881],\n",
       "       [1.        ],\n",
       "       [0.09308922],\n",
       "       [0.09308925],\n",
       "       [0.36940274],\n",
       "       [0.09310386],\n",
       "       [0.99998605],\n",
       "       [0.09310263],\n",
       "       [0.09309116],\n",
       "       [0.09308913],\n",
       "       [0.6411455 ],\n",
       "       [0.1108515 ],\n",
       "       [0.09308881],\n",
       "       [0.09308881],\n",
       "       [0.09309116],\n",
       "       [0.09308925],\n",
       "       [0.09308895],\n",
       "       [0.41815975],\n",
       "       [0.09308881],\n",
       "       [0.09310359],\n",
       "       [1.        ],\n",
       "       [0.09309709],\n",
       "       [0.09308976],\n",
       "       [0.32011288],\n",
       "       [0.09308881],\n",
       "       [0.09310254],\n",
       "       [0.09310398],\n",
       "       [0.2453162 ],\n",
       "       [0.09308967],\n",
       "       [1.        ],\n",
       "       [0.09308925],\n",
       "       [0.09308881],\n",
       "       [0.09308949],\n",
       "       [0.09308881],\n",
       "       [0.09309104],\n",
       "       [1.        ],\n",
       "       [0.42436698],\n",
       "       [0.3201118 ],\n",
       "       [0.9999994 ],\n",
       "       [0.5507722 ],\n",
       "       [1.        ],\n",
       "       [0.7454147 ],\n",
       "       [0.09308925],\n",
       "       [0.09310123],\n",
       "       [0.10557079],\n",
       "       [0.09506127],\n",
       "       [0.09308881],\n",
       "       [1.        ],\n",
       "       [0.386903  ],\n",
       "       [0.09308925],\n",
       "       [0.09308922],\n",
       "       [0.09311521],\n",
       "       [0.09308925],\n",
       "       [0.09308881],\n",
       "       [1.        ],\n",
       "       [0.99931467],\n",
       "       [0.41645077],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.09308913],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.09308925],\n",
       "       [1.        ],\n",
       "       [0.09311157],\n",
       "       [1.        ],\n",
       "       [0.09308931],\n",
       "       [0.09308881],\n",
       "       [0.09309971],\n",
       "       [0.09308958],\n",
       "       [0.22378388],\n",
       "       [0.99999964],\n",
       "       [0.09308895],\n",
       "       [1.        ],\n",
       "       [0.09308895],\n",
       "       [0.98541355],\n",
       "       [0.65128845],\n",
       "       [0.09309003],\n",
       "       [0.5457891 ],\n",
       "       [0.42912072],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.09308904],\n",
       "       [0.21447459],\n",
       "       [0.10027167],\n",
       "       [0.09308931],\n",
       "       [1.        ],\n",
       "       [0.09308985],\n",
       "       [0.09308961],\n",
       "       [0.09308925],\n",
       "       [0.09308943],\n",
       "       [0.09348783],\n",
       "       [1.        ],\n",
       "       [0.09409863],\n",
       "       [0.54887784],\n",
       "       [0.09311676],\n",
       "       [1.        ],\n",
       "       [0.09308925],\n",
       "       [0.99999934],\n",
       "       [0.09312305],\n",
       "       [0.9574126 ],\n",
       "       [0.09312305],\n",
       "       [0.71148694],\n",
       "       [0.16576383],\n",
       "       [0.09309477],\n",
       "       [0.5505562 ],\n",
       "       [0.09308881],\n",
       "       [0.09309408],\n",
       "       [0.09311765],\n",
       "       [1.        ],\n",
       "       [0.09311983],\n",
       "       [0.09308925],\n",
       "       [0.18200749],\n",
       "       [0.09315655],\n",
       "       [0.10375893],\n",
       "       [0.09315783],\n",
       "       [0.15398377],\n",
       "       [1.        ],\n",
       "       [0.74035645],\n",
       "       [0.25656164],\n",
       "       [0.13172382],\n",
       "       [0.09308925],\n",
       "       [0.09308881],\n",
       "       [0.23928574],\n",
       "       [0.9360752 ],\n",
       "       [0.09308881],\n",
       "       [0.99873495],\n",
       "       [0.67957306],\n",
       "       [1.        ],\n",
       "       [0.0931564 ],\n",
       "       [0.09313107],\n",
       "       [0.0930914 ],\n",
       "       [0.09308904],\n",
       "       [0.09308925],\n",
       "       [0.09308925],\n",
       "       [0.09308922],\n",
       "       [0.9999788 ],\n",
       "       [0.09312305],\n",
       "       [0.09308881],\n",
       "       [0.09312305],\n",
       "       [1.        ],\n",
       "       [0.9999937 ],\n",
       "       [0.0930891 ],\n",
       "       [0.09308925],\n",
       "       [0.0937928 ],\n",
       "       [0.09308925],\n",
       "       [0.5466235 ],\n",
       "       [0.0933485 ],\n",
       "       [0.0930903 ],\n",
       "       [0.09308925],\n",
       "       [1.        ],\n",
       "       [0.696928  ],\n",
       "       [0.09308925],\n",
       "       [0.99998426],\n",
       "       [0.09308892],\n",
       "       [0.09308991],\n",
       "       [0.09309754],\n",
       "       [0.09309185],\n",
       "       [0.39922166],\n",
       "       [1.        ],\n",
       "       [0.5505562 ],\n",
       "       [0.19198138],\n",
       "       [0.99999416],\n",
       "       [0.09308881],\n",
       "       [0.09308925],\n",
       "       [0.09329334],\n",
       "       [0.09308925],\n",
       "       [0.09308925],\n",
       "       [0.13869649],\n",
       "       [0.62881774],\n",
       "       [0.09308925],\n",
       "       [0.0930894 ],\n",
       "       [0.09308881],\n",
       "       [0.09308937],\n",
       "       [1.        ],\n",
       "       [0.09308881],\n",
       "       [0.09374681],\n",
       "       [0.09308925],\n",
       "       [0.0930891 ],\n",
       "       [0.09308922],\n",
       "       [0.09308881],\n",
       "       [0.09309131],\n",
       "       [0.5505562 ],\n",
       "       [0.99946284],\n",
       "       [0.09311315],\n",
       "       [1.        ],\n",
       "       [0.09308895],\n",
       "       [0.0974617 ],\n",
       "       [0.09326479],\n",
       "       [0.09310362],\n",
       "       [0.09308925],\n",
       "       [0.09474999],\n",
       "       [1.        ],\n",
       "       [0.71374965],\n",
       "       [0.11281452],\n",
       "       [0.09312689],\n",
       "       [0.09308925],\n",
       "       [0.09308946],\n",
       "       [0.0930894 ],\n",
       "       [0.09308985],\n",
       "       [0.09308895],\n",
       "       [0.9475739 ],\n",
       "       [1.        ],\n",
       "       [0.09309453],\n",
       "       [0.99999917],\n",
       "       [0.09308976],\n",
       "       [0.09310675],\n",
       "       [0.09309915],\n",
       "       [1.        ],\n",
       "       [0.89000076],\n",
       "       [0.09308925],\n",
       "       [0.09424764],\n",
       "       [0.09308922],\n",
       "       [0.22348008],\n",
       "       [0.09309009],\n",
       "       [0.09308881],\n",
       "       [0.09311357],\n",
       "       [0.09308925],\n",
       "       [0.09317279],\n",
       "       [0.0930891 ],\n",
       "       [0.09326044],\n",
       "       [1.        ],\n",
       "       [0.09308881],\n",
       "       [0.7700237 ],\n",
       "       [0.09308895],\n",
       "       [0.09421042],\n",
       "       [0.09308958],\n",
       "       [0.99998987],\n",
       "       [1.        ],\n",
       "       [0.09308904],\n",
       "       [0.09308913],\n",
       "       [0.09308881],\n",
       "       [0.89696455],\n",
       "       [0.70566344],\n",
       "       [0.6769366 ],\n",
       "       [0.09308925],\n",
       "       [0.09308925],\n",
       "       [0.6445786 ],\n",
       "       [0.09308881],\n",
       "       [1.        ],\n",
       "       [0.99998987],\n",
       "       [0.09308925],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.09308881],\n",
       "       [0.14064357],\n",
       "       [1.        ],\n",
       "       [0.09308895],\n",
       "       [0.09367827],\n",
       "       [1.        ],\n",
       "       [0.09317094],\n",
       "       [0.09310451],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.09366879],\n",
       "       [0.09309709],\n",
       "       [0.278512  ],\n",
       "       [0.09308881],\n",
       "       [0.09308925],\n",
       "       [0.09308937],\n",
       "       [0.44516167],\n",
       "       [0.28200313],\n",
       "       [0.09308913],\n",
       "       [1.        ],\n",
       "       [0.09309116],\n",
       "       [0.09309003],\n",
       "       [0.09312299],\n",
       "       [0.09308881],\n",
       "       [0.09308881],\n",
       "       [0.9999981 ],\n",
       "       [0.2073619 ],\n",
       "       [0.09309599],\n",
       "       [0.09308881],\n",
       "       [1.        ],\n",
       "       [0.09309104],\n",
       "       [1.        ],\n",
       "       [0.09310386],\n",
       "       [0.09308922],\n",
       "       [1.        ],\n",
       "       [0.0930998 ],\n",
       "       [1.        ],\n",
       "       [0.9993378 ],\n",
       "       [0.9994286 ],\n",
       "       [0.09311682],\n",
       "       [0.09332773],\n",
       "       [1.        ],\n",
       "       [0.55093277],\n",
       "       [0.99850935],\n",
       "       [0.5505562 ],\n",
       "       [1.        ],\n",
       "       [0.88576496],\n",
       "       [0.09308925],\n",
       "       [1.        ],\n",
       "       [0.09308881],\n",
       "       [0.09308931],\n",
       "       [0.09308881]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[]\n",
    "for i in range(418):\n",
    "    A.append([int(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans=np.stack((A,Y_pred),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"text\",Ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ai_ml_nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75f149aabefc45f596bad3ecd1cce999665dc47c609d2b6ed1c0c06088326543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
